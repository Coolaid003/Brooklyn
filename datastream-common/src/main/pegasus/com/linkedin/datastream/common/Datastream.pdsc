{
  "type": "record",
  "name": "Datastream",
  "namespace": "com.linkedin.datastream.common",
  "doc": "Extensible data model of Datastream",
  "fields": [
    {
      "name": "name",
      "doc": "Name of the Datastream.",
      "type": "string"
    },
    {
      "name": "connectorType",
      "doc": "Type of the connector to be used for reading the change capture events from the source, e.g. Oracle-Change, Espresso-Change, Oracle-Bootstrap, Espresso-Bootstrap, Mysql-Change etc..",
      "type": "string"
    },
    {
      "name": "source",
      "doc": "Source that connector can use to connect to the data store and consume the data.",
      "type": {
        "type": "record",
        "name": "DatastreamSource",
        "doc": "Datastream source that connector will use to consume events",
        "fields": [
          {
            "name": "connectionString",
            "doc": "Source connection string to consume the data from.",
            "type": "string"
          }
        ]
      }
    },
    {
      "name": "destination",
      "doc": "Datastream destination string that the transport provider will use to send the events",
      "type": {
        "type": "record",
        "name": "DatastreamDestination",
        "doc": "Datastream destination details that the transport provider will use to send events",
        "fields": [
          {
            "name": "connectionString",
            "doc": "Source connection string to consume the data from.",
            "type": "string"
          },
          {
            "name": "partitions",
            "doc": "Number of partitions of the kafka topic.",
            "type": "int"
          }
        ]
      },
      "optional": true
    },
    {
      "name": "metadata",
      "doc": "Generic metadata for Datastream (e.g. owner, expiration, etc). Metadatas are stored as user defined name/value pair.",
      "type": {
        "type": "map",
        "values": "string"
      },
      "optional": true
    }
  ]
}
